---
title: "hCoCena - STAR protocol (main)"
author: "Marie Oestreich, Lisa Holsten, Kilian Dahm"
date: "19 10 2023"
output:
  html_document: default
  pdf_document: default
---


# 0 Introduction
  This markdown, in combination with the markdown 'hcocena_satellite_STARprotocol.Rmd', illustrates how to use the hCoCena tool on a small example using two data sets based on the hcocena package version 1.2.
Both data sets measure the transcriptional profiles of human macrophages after treatment with Interferon Gamma (IFNg), Interleukin-4 (IL4) or untreated (baseline). One data set was generated using bulk RNA-sequencing, while the other was generated using a Microarray.

The main Markdown contains the base workflow of hCoCena. For a fully functional analysis, these steps are mandatory unless declared otherwise (flagged with OPTIONAL). Feel free to expand upon this base analysis with the provided satellite functions or your custom scripts. You will find detailed information on the satellite functions as well as intermediate outputs that you can use for your custom analyses in the repository's Wiki (https://github.com/MarieOestreich/hCoCena/wiki).


# 1 Pre-Integration Phase
  This part includes all the steps that lead up to the actual integration procedure of the data sets.

## 1.1 Load hCoCena package

  First, we are going to load the hCoCena R-package. For information on how to download and install the package, please refer to the 'install_hcocena.R' script that you can find in the Github repository.

```{r}
# library(hcocena)

# Until package is updated:
file.sources <- list.files(path = "C:/Users/dahmk/Projects/hCoCena/hCoCena/hCoCena-r-package/R/",
                           pattern = "*.R", full.names = T)
sapply(file.sources, source, .GlobalEnv)
rm(file.sources)

library(magrittr)
```


## 1.2 Create the hCoCena Object

  Now, we will create the 'hcobject'. This is an object structure specifically designed for the hCoCena analysis and it will store all intermediate results of the analysis in a unified structure. For more information on the structure, please refer to the Wiki: https://github.com/MarieOestreich/hCoCena/wiki/Structure-of-the-hcobject.
  The object will automatically be generated by running the function below. No parameters need to be set. 

```{r}
init_object()
```


## 1.3 Set-up of the working directory

  In this step, we will indicate to hCoCena where it can find everything we need for the analysis: Our gene expression data (count data), our meta data (annotation), and our reference files. These will be used for example for highlighting transcription factors or doing enrichment analyses. For more information on the different files and how to pass them to the function, please refer to the following section of the wiki: https://github.com/MarieOestreich/hCoCena/wiki/General-Backgroud-Information#count-files-annotation-files--reference-files.
  
  In this example case, we will not read the expression data and the annotation from files, but instead use an R environment that we have prepared for the STAR protocol. You can find the environment in the repository's 'STAR_protocol' folder, it is named 'start_envo.RData'. After downloading, we can load the environment like this:
  
```{r}

load(paste0(getwd(), "/start_envo.RData"))

```
  

  Since we are not reading our data from files, we will set the directory for the count data ('dir_count_data'), as well as for the annotation ('dir_annotation') to FALSE. My reference files are stored within the "hcocena" folder, which also holds the folder STAR_protocol from where I am running this markdown. Hence the parameter 'dir_reference_files' is set accordingly. The files can be downloaded from the Github repository folder named 'reference files', after downloading, the path must be adapted according to where it was downloaded to.

  Lastly, we define a directory where we want to create our analysis folder. Within my "hcocena" folder, which contains the "STAR_protocol" folder with my scripts and the R environment, I also have a folder "analyses" where I store the results for my different analyses. In this folder, hCoCena will create a new folder specifically for this analysis and store all plots and other outputs there.


```{r}

dir <- getwd() %>% stringr::str_remove(pattern = "/STAR_protocol")

init_wd(dir_count_data = FALSE,
        dir_annotation = FALSE,
        dir_reference_files = paste0(dir, "/reference files/"), #the folder that contains the reference files
        dir_output = paste0(dir, "/analyses/"))

rm(dir)

```


  The following function assures that all directories given above exist and fixes missing slashes at the end. It requires no parameters. If a directory does not exist (might just be a typo!) it will produce an error.

```{r check directories}

check_dirs()

```


  In the next step we are going to choose a name for the folder that hCoCena creates for our analysis (in the directory that we set in init_wd: dir_output).Since this is the script to the STAR protocol, I'll call it 'STAR_protocol':
  
```{r, warning = FALSE}

init_save_folder(name = "STAR_protocol")

```


## 1.4 Defining layers

  Now, we provide the count and annotation data for the different data sets ('layers'): The function 'define_layers()' accepts as input a named list. The names of the list elements should be descriptive of the respective data set. Here, we name one list element 'Array' (it will hold the microarray data and annotation) and the other 'RNA_seq' (RNA-seq data and annotation). Each of these elements is set to be a vector of 2 strings: the first being the name of the count data file/dataframe, the second for the annotation file/dataframe. Since we are loading the data from dataframes in the environment (not from files), the given strings (e.g., "data_array", "annotation_array") are the names of objects. For detailed information regarding the structures of the count and annotation data as well as different options for providing data, refer to the function documentation by entering ?hcocena::define_layers into the console.
  
  Secondly, we provide the names of supplementary files containing Transcription Factors ('Tf'), Hallmark enrichment terms ('Hallmark'), Kegg enrichment terms ('Kegg') and GO BP enrichment terms ('Go'). These files should be stored in the 'reference_files' folder that we set in 'init_wd()'. The files can be downloaded from the Github repository, you will find them in the folder named 'reference files'. You can check the MSidDB website for the most current versions of the pathway to gene files. Further, custom pathway to gene files saved in the 'reference_files' folder in a '.gmt' or '.csv' file format can read. Files should be in the following format:
  1. column (named 'term'): name of the pathway
  2. column (named 'gene'): gene symbol of the respective pathway defined in the first column
Note: Only one gene symbol per row is allowed, thus, in cases where multiple genes are associated with a pathway generate one row per gene symbol!
    
```{r defining Omics Layers}

define_layers(list(Array = c("data_array", "annotation_array"),
                   RNA_Seq = c("data_seq", "annotation_seq")))

set_supp_files(Tf = "TFcat.txt", 
               Hallmark = "h.all.v2023.1.Hs.symbols.gmt", 
               Go = "c5.go.bp.v2023.1.Hs.symbols.gmt",
               Kegg = "c2.cp.kegg.v2023.1.Hs.symbols.gmt")

```


## 1.5 Data import

  After telling hCoCena where to find all the data and supplementary data that we need for the analysis, they are now loaded and stored in the 'hcobject', where the tool can access them throughout the analysis without cluttering the environment. The 'read_data()' function offers a series of parameters, such as the separator of the count file etc. However, since we are loading our data from data frames in our environment, none of these parameters are necessary.
  If you are reading your data from file and are looking for more detailed information regarding the different parameters, enter ?hcocena::read_data into the console.

```{r data import}

read_data()

read_supplementary()

```


## 1.6 Define global settings

  In this chunk, we will define the so-called 'global settings'. Those are all the settings that are **dataset independent**. In our case, we will set the organism to be 'human' since we have human macrophage data for our showcase (so far, only human and mouse are supported). We will set the control keyword to 'none'. We do have controls in our dataset that we could use as a reference for the Group-Fold-Change analyses later on, but then we loose the control group since they serve as a reference. Here, we will keep them as a separate group to include them in our results, which will allow us to compare the baselines from the two datasets as well (this is a personal analysis choice). As the variable of interest (voi), we choose 'merged' since that is the name of the column in both our annotation dataframes that we want to use to group the samples. It contains information on the treatment of a sample as well as the dataset the sample originates from. We further define that we are only interested in networks and modules that contain at least 25 genes, we set the range of the GFC values to be from -2 to 2, the layout algorithm to be 'cytoscape' (you can change this, if you don't have Cytoscape installed, however the networks always look more readable and high-quality with Cytoscape) and data_in_log is TRUE, because our gene expression data has been logged to the base of 2 in the pre-processing. For more detailed information regarding the different settings and what other options are available, enter ?hcocena::set_global_settings into the console.

```{r global settings}

set_global_settings(organism = "human", 
    								control_keyword = "none", 
    								variable_of_interest = "merged", 
    								min_nodes_number_for_network = 25, 
    								min_nodes_number_for_cluster = 25,
    								range_GFC = 2.0,
    								layout_algorithm = "cytoscape",
    								data_in_log = T)

```



## OPTIONAL: Data-based definition of top most variant genes

  This chunk in the satellite markdown ('hcocena_satellite_STAR_protocol.Rmd') calculates the inflection points in the ranked variances to filter for the top most variant genes in a data-driven way. Running this function yields top 7700 for the array data and 7664 for the RNA-Seq data as the highest data-driven top-most-variant genes cutoff. 


## 1.7 Define layer-specific settings

  After defining the global (dataset-independent) settings in section 1.6, we will now define those **specific for each dataset**. We start with selecting the top most-variable genes to keep based on the chunk we just ran in the satellite markdown. You can also set this to 'all' if you don't want to pre-filter your genes. We further define that we are interested in all gene pairs with minimum correlation 0.9 and that we want to inspect 50 different cutoffs between 0.9 and 1. We don't want to see the node-degree distribution plot for all of those 50 cutoffs, so we set that parameter to FALSE.
  For detailed information regarding the different settings, enter ?hcocena::set_layer_settings into the console.
  

```{r layer-specific settings}

# 7700 and 7664 are selected based on suggestions by the suggest_topvar() function in the satellite markdown

set_layer_settings(top_var = c(7700, 7664), 
                   min_corr = c(0.9, 0.9), 
                   range_cutoff_length = c(50, 50),
                   print_distribution_plots = c(F, F))

```



## OPTIONAL: Data distribution

  There is an option to plot the distribution of counts for each sample to check for outliers or prominent differences between samples. To do so, refer to "Data distribution" in the satellite markdown.
  
  
## OPTIONAL: PCA

  You can visualize your data in a PCA. To do so, please refer to the satellite markdown, section "PCA".
  

## OPTIONAL: Meta data visualization

  You can visualize your meta data using the "Meta data distribution" section in the satellite markdown.
  

## 1.8 Data processing part I

  This function executes the first part of the data processing procedure. It leads up to choosing the correlation cut-off for each layer. All datasets will be filtered for their most variant genes as defined in the layer-specific settings. After this filtering step, the pair-wise correlation for all pairs of genes is calculated. You can set the correlation metric that you would like to use with the 'corr_method' parameter. Options are: 'pearson', 'spearman' and 'rho' (Skinnider et al., https://doi.org/10.1038/s41592-019-0372-4). We will pick 'spearman'.
  A set of statistics will be calculated for the set range of cut-off values that aim to facilitate the cut-off choice. This includes determining the number of graph components resulting from creating a network when cutting the data with the respective cut-off, as well as the number of nodes and edges this network comprises. The last parameter that is evaluated is the RÂ²-value of the data to a linear regression through the logged degree distribution for the given network. These parameters will be visualised in the next step.
  For detailed information on what happens in this step and what parameters can be set, enter ?hcocena::run_expression_analysis_1 into the console.

```{r expression analysis up to cutoff}

run_expression_analysis_1(corr_method = "spearman")

```



## 1.9 Data processing part II

  **Choosing the cut-offs**
  
  Set a correlation cut-off for each of your data sets. To aid the choice of a correlation cut-off for each of the datasets, the following plot presents the different cut-off statistics calculated in the previous step per data set.
  Generally, we have the choice between a static and an interactive plot. The interactive plot (which we use here by setting interactive = TRUE) is a widget that allows you to slide through the different cutoffs and highlight the corresponding statistics. However, if R-Studio is having difficulties displaying widgets, use interactive = FALSE for a simple ggplot.
  
```{r fig.height = 8, fig.width = 10}

plot_cutoffs(interactive = T)

```
  
  
  Given the drastic drop in R-squared value as well as the number of genes for cutoffs higher than 0.982 in both datasets, we will select 0.982 as our cutoff in both cases. The order in which the cutoffs are subsequently defined must correspond to the order in which the layers have previously been specified.

```{r choose cutoff}

set_cutoff(cutoff_vector = c(0.982, 0.982))

```


  **Checking the scale-free topology**

  For each data set, the logged degree distribution and the linear regression are plotted to visualize the preservation of the scale-free topology criterion.
  NOTE: Even though biological networks are generally believed to follow a scale-free topology, experience has shown that a lot of transcriptomics data does not follow this principle perfectly. A deviation from the regression line is often observed at higher x-axis values. 

```{r plot degree distribution for chosen cutoff, message = F, warning = F}

plot_deg_dist()

```


  **Heatmap of top most variant genes and GFC calculation**

  This function plots a heatmap for the network genes in each data layer and computes the Group-Fold-Changes (GFCs) for each gene per layer.

```{r, fig.width = 10, fig.height = 7}

run_expression_analysis_2(cols = list("merged" = c("IL4_array" = "#00A1D5FF", "IFNg_array" = "#79AF97FF", "baseline_array" = "#374E55FF",
                                                   "IL4_seq" = "#00A1D5FF", "IFNg_seq" = "#79AF97FF", "baseline_seq" = "#374E55FF")))

```



# 2 Integration Phase
  
  Here, the previously constructed layer-specific networks will be integrated into one network that combines the information. The integration can be based on the union or intersection of layer-specific networks. Edges that are present in several networks at different lengths can be included based on different options. For detailed information on available parameters, run ?hcocena::build_integrated_network in the console. 
  
  Here, we are integrating our datasets using the union of their two networks (mode = "u"), meaning we will also include nodes and edges that are only present in one dataset but not the other. This way, we get an idea not only of shared aspects across the datasets but also of those that are unique. If an edge (i.e., a cut-off exceeding correlation between two genes) exists in both networks, and the correlation value is not the same in both cases, we are using the minimum edge weight (correlation) in the integrated network (multi_edges = "min"). This way, we are being cautious about the true importance of their co-expression and we are making the network less dense (lower correlations = longer edges), making it easier to find true communities (i.e. clusters of densely connected genes across datasets) in the network.
  
```{r merge networks}

build_integrated_network(mode = "u", multi_edges = "min")

```


# 3 Post-Integration Phase

## 3.1 Module detection
  
  In this step, modules of strong co-expression will be detected in the network and their expression pattern across conditions will be represented in a GFC heatmap. For more information on the available clustering algorithms, run ?hcocena::cluster_calculation and visit the repository's Wiki pages.
  NOTE: You can export your clustering for future use. To do so, please refer to the satellite script, section "Export clustering".
  NOTE 2: Instead of clustering your network here, you can alternatively import a clustering model. To do so, please use the import_clusters() function (see satellite markdown for more  information).
  
  Here, we will cluster our integrated network using the default clustering algorithm (Leiden). We will run the clustering 50 times (no_of_iterations = 50), we will leave the maximum cluster count per gene at its default value (1), meaning we only keep genes that can be associated with the same cluster in all runs. Plot_cluster_heatmap() then plots the result.
  
```{r compute clusters}
cluster_calculation(no_of_iterations = 50, cluster_algo = "cluster_leiden", resolution = 1)

plot_cluster_heatmap()
```


## OPTIONAL: Module scores

  If you would like to evaluate how well each gene belongs to its asserted module, please refer to the satellite markdown, section "Module scores".
  

## OPTIONAL: Evaluating the different community detection algorithms

  If you want to compare the default Louvain clustering to other algorithms, please refer to the section "Evaluating different community detection algorithms" in the satellite markdown.


## 3.2 Plotting the network coloured by module

  Since we picked Cytoscape as the layout option for our network, we will not plot the network with genes coloured according to modules here. Instead, we move to the 'Cytoscape' section in the hcocena_satellite_STARprotocol.Rmd. There, we export the network to Cytoscape, apply the layout within cytoscape, and re-import the network into R. This is a bit of extra work, but the superiority of the layouts in Cytoscape is worth it. If you don't have Cytoscape installed or are happy with a visually less intuitive network, you can use this chunk instead of going to the satellite markdown. However, then you also have to  set the 'layout_algorithm' parameter in the 'set_global_settings()' function (quite at the top) to 'layout_with_fr'. 
  Please note that the layout has no effect on the modules themselves or on the subsequent analysis results! It is simply to generate a visual 2D representation of the network that shows the spatial arrangement of the modules. 

```{r plot network coloured by module, fig.width=10, fig.height=7}
# Cytoscape option used (see satellite markdown)

plot_integrated_network() 

```


## OPTIONAL: Plotting network coloured by GFC

  You can re-plot the network for each condition (variable of interest) colouring the nodes according to their GFC in the different conditions. To do so, please refer to the section "Plotting network coloured by GFC" in the satellite markdown. 
  In our showcase example, this will show us, how the GFCs of each gene change across the different treatments of the Macrophages and between Array and RNA-Seq.
  

## 3.3 Database enrichment

  Enrichment analysis of the modules using the GO, KEGG, Hallmark and Reactome databases. For detailed information on parameter settings, please run ?hcocena::functional_enrichment.
  
  In our case, we are interested in getting the GO- and HALLMARK enrichment for selected modules of interest (we selected them because of their stimulus-specific activation patterns). In both cases, we want to retrieve the top 5 most enriched terms (may be less if less than 5 terms are enriched). We also filter the results for those with adjusted p-values not higher than 0.1. 
  
```{r GO profiling, fig.width = 8, fig.height = 7, message = F, warning = F}

functional_enrichment(gene_sets = c("Hallmark"), 
                      clusters = c("seagreen", "steelblue", "turquoise", "plum", "maroon", "lightblue", "gold"),
                      top = 5, 
                      padj = "BH", 
                      qval = 0.1)

```


## 3.4 Transcription factor enrichment analyses with ChEA3

  Transcription factor (TF) enrichment analysis can be performed separately for each module ('TF_overrep_module') based on ChEA3 (Kennan AB, 2019). For more details, refer to the function documentations with ?hcocena::TF_overrep_module. The plots can be found in the save folder, descriptions on how to read them can be found within the documentation.
  
  NOTE: hCoCena is accessing a database in this step. The contents of the database may change over time as the biological insight progresses. Hence, results might change over time based on changes to the database. That is not a bug in the hCoCena tool. It may also occur, that the database is momentarily unavailable due to maintanence or updates. Before running the chunk, you can check, if the server is running properly or currently under maintenance using this link: https://maayanlab.cloud/chea3/api/enrich/.
  
  NOTE 2: The results of this function are directly printed to a PDF file in your output folder.
  
  
```{r , fig.width = 10, fig.height = 7}

TF_overrep_module(clusters = c("lightblue"),
                  topTF = 5, 
                  topTarget = 5)

```
 
 
## OPTIONAL: Transcription factor enrichment analysis based on the entire network

  The transcription factor enrichment analysis can also be performed network wide. Please refer to the satellite markdown, section "Transcription factor enrichment network".


## OPTIONAL: Hub gene detection

  Hub gene detection is available for selected modules or the entire network. Please refer to the satellite markdown, section "Hub gene detection".
  

## OPTIONAL: Expression of a specific gene set

  You can plot the mean expression values per condition for a list of genes as a heatmap.
  You find the corresponding function in the satellite markdown under "Visualize specific gene set".
  
  
## OPTIONAL: Colour specific gene set within the network

  You further have the option of replotting the network and highlighting a particular gene set. To do so, please refer to the satellite markdown, section "Colour specific gene set".
  
  
## OPTIONAL: Colour single module within the network

  You can plot the network with a module of interest highlighted (colour and node size), using the chunk in the satellite markdown in section "Colour single module".
  

## OPTIONAL: Correlate numeric or categorical meta data with modules

  To see how numeric or categorical meta information correlates to the expression patterns of a module, refer to the satellite markdown, section "Correlate numeric meta data with modules" and "Correlate categorical meta data with modules", respectively.


## OPTIONAL: Module analysis and meta-annotation

  You have the option to analyse the genes present in the found modules with regard to shared functionality or enriched gene sets as well as to annotate the groups of samples with meta information from your annotation file. To do so, please refer to the satelite markdown, section "Module analysis and meta-annotation".


## OPTIONAL: Replotting of heatmap with different variable of interest

  In case you are uncertain if the "voi" you have initially chosen is the right choice for your analysis, you are given the opportunity to replot the final module heatmap based on a different annotation variable. To do so, please refer to the section "Replotting of heatmap with different variable of interest" in the satellite markdown.


## OPTIONAL: Regrouping samples

  If you noticed that the variable of interest ("voi") does not go well with the clustering of the heatmaps returned by "run_expression_analysis_2" or as seen in the PCA, when evaluating different clustering algorithms, you can assign new group labels to your samples based on the data structure rather than meta information. In this case, please refer to the section "Regrouping samples" in the satellite markdown.


## OPTIONAL: Final module heatmap and network

  If you regrouped your samples AND/OR conducted any steps in the "Module analysis and meta-annotation"-section, the heatmap will be replotted updated with respect to the grouping and annotation information along with the network coloured by modules. If You have neither regrouped your sample nor analysed your modules or samples groups, this chunk will provide the exact same output as the previous one and can be skipped. 
  
```{r create module heatmap, fig.width = 10, fig.height = 7}

plot_cluster_heatmap()

plot_integrated_network(layout = hcobject[["integrated_output"]][["cluster_calc"]][["layout"]], 
                        save = F)

```


# 4. Save essential information

  The parameters of the analysis session are written to a text file to enhance reproducibility without keeping and sharing a markdown for every analysis. It documents the name of the files and their location used as count and annotation files, the global settings set in the session, the layer settings set for each dataset as well as the cut-offs and the clustering algorithm used. 
  The file can be found in the save-folder.
  
```{r write session info}

write_session_info()

```





